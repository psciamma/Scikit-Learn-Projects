{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path=\"C:\\\\Users\\jsciamma\\Documents\\Patrick\\ML\\Kaggle\\Titanic\"\n",
    "path=\"C:\\\\Users\\Patrick\\ML\\Titanic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Patrick\\\\ML\\\\Titanic'"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(path)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data\\\\train.csv\")\n",
    "test = pd.read_csv(\"data\\\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 11)"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 66.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 27.8+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 0 entries\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    0 non-null int64\n",
      "Survived       0 non-null int64\n",
      "Pclass         0 non-null int64\n",
      "Name           0 non-null object\n",
      "Sex            0 non-null object\n",
      "Age            0 non-null float64\n",
      "SibSp          0 non-null int64\n",
      "Parch          0 non-null int64\n",
      "Ticket         0 non-null object\n",
      "Fare           0 non-null float64\n",
      "Cabin          0 non-null object\n",
      "Embarked       0 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 0.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "pd.merge(train, test).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr              517\n",
      "Miss            182\n",
      "Mrs             125\n",
      "Master           40\n",
      "Dr                7\n",
      "Rev               6\n",
      "Mlle              2\n",
      "Major             2\n",
      "Col               2\n",
      "Mme               1\n",
      "Jonkheer          1\n",
      "Capt              1\n",
      "Don               1\n",
      "Lady              1\n",
      "Sir               1\n",
      "the Countess      1\n",
      "Ms                1\n",
      "Name: Name, dtype: int64\n",
      "null values 0\n",
      "Series([], Name: Name, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "s = train.Name.str.extract(',\\s+([\\w\\s]+)\\.', expand=False)\n",
    "print(s.value_counts())\n",
    "print(\"null values\", sum(s.isnull()))\n",
    "print(train.Name[s.isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr        531\n",
       "Miss      185\n",
       "Mrs       129\n",
       "Master     40\n",
       "Rev         6\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_title(s, Sex):\n",
    "    if s in { 'Major', 'Col', 'Sir', 'Don', 'Capt', 'Jonkheer'}:\n",
    "        return 'Mr'\n",
    "    if s in {'Mlle', 'Ms'}:\n",
    "        return 'Miss'\n",
    "    if s in {'Mme', 'Lady', 'the Countess'}:\n",
    "        return 'Mrs'\n",
    "    if s == 'Dr':\n",
    "        if Sex == \"male\":\n",
    "            return \"Mr\"\n",
    "        else:\n",
    "            return \"Mrs\"\n",
    "    return s\n",
    "\n",
    "#print(list(zip(s.unique(),map(convert_title, s.unique()))))\n",
    "train['Title'] = list(map(convert_title, s, train.Sex))\n",
    "train.Title.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract last name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>WomanInThird</th>\n",
       "      <th>ManInFirst</th>\n",
       "      <th>LastName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Master. Thomas Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Master</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Miss. Constance Gladys</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Sage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>325</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Mr. George John Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>793</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Miss. Stella Anna</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Sage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>847</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Mr. Douglas Bullen</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>864</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Miss. Dorothy Edith \"Dolly\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Sage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                               Name     Sex  \\\n",
       "159          160         0       3         Sage, Master. Thomas Henry    male   \n",
       "180          181         0       3       Sage, Miss. Constance Gladys  female   \n",
       "201          202         0       3                Sage, Mr. Frederick    male   \n",
       "324          325         0       3           Sage, Mr. George John Jr    male   \n",
       "792          793         0       3            Sage, Miss. Stella Anna  female   \n",
       "846          847         0       3           Sage, Mr. Douglas Bullen    male   \n",
       "863          864         0       3  Sage, Miss. Dorothy Edith \"Dolly\"  female   \n",
       "\n",
       "     Age  SibSp  Parch    Ticket   Fare Cabin Embarked   Title  WomanInThird  \\\n",
       "159  NaN      8      2  CA. 2343  69.55   NaN        S  Master         False   \n",
       "180  NaN      8      2  CA. 2343  69.55   NaN        S    Miss          True   \n",
       "201  NaN      8      2  CA. 2343  69.55   NaN        S      Mr         False   \n",
       "324  NaN      8      2  CA. 2343  69.55   NaN        S      Mr         False   \n",
       "792  NaN      8      2  CA. 2343  69.55   NaN        S    Miss          True   \n",
       "846  NaN      8      2  CA. 2343  69.55   NaN        S      Mr         False   \n",
       "863  NaN      8      2  CA. 2343  69.55   NaN        S    Miss          True   \n",
       "\n",
       "     ManInFirst LastName  \n",
       "159       False     Sage  \n",
       "180       False     Sage  \n",
       "201       False     Sage  \n",
       "324       False     Sage  \n",
       "792       False     Sage  \n",
       "846       False     Sage  \n",
       "863       False     Sage  "
      ]
     },
     "execution_count": 725,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = train.Name.str.extract('^([\\w\\s\\-\\']+),', expand=False)\n",
    "#print(s.value_counts())\n",
    "#print(\"null values\", sum(s.isnull()))\n",
    "#print(train.Name[s.isnull()])\n",
    "train['LastName'] = s\n",
    "train.LastName.value_counts()\n",
    "train[train.LastName=='Sage']\n",
    "#train[train.Ticket=='3101281']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check and correct Embarked null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>WomanInThird</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Icard, Miss. Amelie</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Miss</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>830</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stone, Mrs. George Nelson (Martha Evelyn)</td>\n",
       "      <td>female</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                       Name  \\\n",
       "61            62         1       1                        Icard, Miss. Amelie   \n",
       "829          830         1       1  Stone, Mrs. George Nelson (Martha Evelyn)   \n",
       "\n",
       "        Sex   Age  SibSp  Parch  Ticket  Fare Cabin Embarked Title  \\\n",
       "61   female  38.0      0      0  113572  80.0   B28      NaN  Miss   \n",
       "829  female  62.0      0      0  113572  80.0   B28      NaN   Mrs   \n",
       "\n",
       "     WomanInThird  \n",
       "61          False  \n",
       "829         False  "
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check and correct null Embarked values\n",
    "train[train['Embarked'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Embarked</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>104.718529</td>\n",
       "      <td>90.0</td>\n",
       "      <td>70.364862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Embarked           C     Q          S\n",
       "Fare      104.718529  90.0  70.364862"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(train[train.Pclass==1], values='Fare', columns = 'Embarked', aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <th colspan=\"2\" halign=\"left\">1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Master</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.392857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss</th>\n",
       "      <td>0.958333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.086022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.112853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs</th>\n",
       "      <td>0.978261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rev</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pclass         1                   2                3          \n",
       "Sex       female      male    female      male female      male\n",
       "Title                                                          \n",
       "Master       NaN  1.000000       NaN  1.000000    NaN  0.392857\n",
       "Miss    0.958333       NaN  0.942857       NaN    0.5       NaN\n",
       "Mr           NaN  0.352941       NaN  0.086022    NaN  0.112853\n",
       "Mrs     0.978261       NaN  0.902439       NaN    0.5       NaN\n",
       "Rev          NaN       NaN       NaN  0.000000    NaN       NaN"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(train, values='Survived', columns = ['Pclass', 'Sex'], index='Title', aggfunc='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add dummy variables for women in 3rd class and men in first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['WomanInThird'] = (train.Sex=='female') & (train.Pclass==3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['ManInFirst'] = (train.Title=='Mr') & (train.Pclass==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <th colspan=\"2\" halign=\"left\">1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Master</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss</th>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>119.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs</th>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rev</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pclass      1             2            3       \n",
       "Sex    female   male female  male female   male\n",
       "Title                                          \n",
       "Master    NaN    3.0    NaN   9.0    NaN   28.0\n",
       "Miss     48.0    NaN   35.0   NaN  102.0    NaN\n",
       "Mr        NaN  119.0    NaN  93.0    NaN  319.0\n",
       "Mrs      46.0    NaN   41.0   NaN   42.0    NaN\n",
       "Rev       NaN    NaN    NaN   6.0    NaN    NaN"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(train, values='Survived', columns = ['Pclass', 'Sex'], index='Title', aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Parch</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Parch    0    1         2\n",
       "SibSp                    \n",
       "0      NaN  1.0  1.000000\n",
       "1      1.0  1.0  1.000000\n",
       "3      NaN  0.0  0.000000\n",
       "4      NaN  0.0  0.333333\n",
       "5      NaN  NaN  0.000000\n",
       "8      NaN  NaN  0.000000"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(train[(train.Title=='Master') & (train.Pclass==3)], values='Survived', columns = ['Parch'], index=['SibSp'], aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Master</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Miss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Title Master                               Miss                          \n",
       "SibSp      0    1    3         4    5         0         1    2    3     4\n",
       "Parch                                                                    \n",
       "0        NaN  NaN  NaN       NaN  NaN  1.000000       NaN  NaN  NaN   NaN\n",
       "1        1.0  1.0  0.0  0.000000  NaN  0.666667  0.666667  1.0  0.0   NaN\n",
       "2        1.0  1.0  0.0  0.333333  0.0  1.000000       NaN  0.0  0.0  0.25"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(train[(train.Age<10) & (train.Pclass==3)], values='Survived', columns = ['Title', 'SibSp'], index=['Parch'], aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId                      62\n",
      "Survived                          1\n",
      "Pclass                            1\n",
      "Name            Icard, Miss. Amelie\n",
      "Sex                          female\n",
      "Age                              38\n",
      "SibSp                             0\n",
      "Parch                             0\n",
      "Ticket                       113572\n",
      "Fare                             80\n",
      "Cabin                           B28\n",
      "Embarked                          S\n",
      "Title                          Miss\n",
      "WomanInThird                  False\n",
      "Name: 61, dtype: object\n",
      "PassengerId                                           830\n",
      "Survived                                                1\n",
      "Pclass                                                  1\n",
      "Name            Stone, Mrs. George Nelson (Martha Evelyn)\n",
      "Sex                                                female\n",
      "Age                                                    62\n",
      "SibSp                                                   0\n",
      "Parch                                                   0\n",
      "Ticket                                             113572\n",
      "Fare                                                   80\n",
      "Cabin                                                 B28\n",
      "Embarked                                                S\n",
      "Title                                                 Mrs\n",
      "WomanInThird                                        False\n",
      "Name: 829, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# passengers 62 and 830\n",
    "train.at[61, 'Embarked'] = \"S\"\n",
    "print(train.iloc[61])\n",
    "train.at[829, 'Embarked'] = \"S\"\n",
    "print(train.iloc[829])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x0000009FAD0FB4A8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000009FAD384F98>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000009FAD2EB390>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x0000009FAD491630>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000009FAD4E2550>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000009FAD4E2588>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x0000009FAD5A3F28>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000009FAD6175F8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000009FAD675C18>]], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABI8AAANhCAYAAABuHJt+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAwJDwCAAAAYOj/A9pcTM06SGKKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9fad2c92b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "train.hist(bins=50, figsize=(20,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Leonard, Mr. Lionel</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LINE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Harrison, Mr. William</td>\n",
       "      <td>male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B94</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>272</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Tornquist, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LINE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>278</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Parkes, Mr. Francis \"Frank\"</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>303</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mr. William Cahoone Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LINE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>414</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Cunningham, Mr. Alfred Fleming</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>467</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Campbell, Mr. William</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>482</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Frost, Mr. Anthony Wood \"Archie\"</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>598</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mr. Alfred</td>\n",
       "      <td>male</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LINE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>634</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Parr, Mr. William Henry Marsh</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>675</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Watson, Mr. Ennis Hastings</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>733</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Knight, Mr. Robert J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>807</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Andrews, Mr. Thomas Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A36</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>816</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fry, Mr. Richard</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B102</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>823</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Reuchlin, Jonkheer. John George</td>\n",
       "      <td>male</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                              Name   Sex  \\\n",
       "179          180         0       3               Leonard, Mr. Lionel  male   \n",
       "263          264         0       1             Harrison, Mr. William  male   \n",
       "271          272         1       3      Tornquist, Mr. William Henry  male   \n",
       "277          278         0       2       Parkes, Mr. Francis \"Frank\"  male   \n",
       "302          303         0       3   Johnson, Mr. William Cahoone Jr  male   \n",
       "413          414         0       2    Cunningham, Mr. Alfred Fleming  male   \n",
       "466          467         0       2             Campbell, Mr. William  male   \n",
       "481          482         0       2  Frost, Mr. Anthony Wood \"Archie\"  male   \n",
       "597          598         0       3               Johnson, Mr. Alfred  male   \n",
       "633          634         0       1     Parr, Mr. William Henry Marsh  male   \n",
       "674          675         0       2        Watson, Mr. Ennis Hastings  male   \n",
       "732          733         0       2              Knight, Mr. Robert J  male   \n",
       "806          807         0       1            Andrews, Mr. Thomas Jr  male   \n",
       "815          816         0       1                  Fry, Mr. Richard  male   \n",
       "822          823         0       1   Reuchlin, Jonkheer. John George  male   \n",
       "\n",
       "      Age  SibSp  Parch  Ticket  Fare Cabin Embarked  \n",
       "179  36.0      0      0    LINE   0.0   NaN        S  \n",
       "263  40.0      0      0  112059   0.0   B94        S  \n",
       "271  25.0      0      0    LINE   0.0   NaN        S  \n",
       "277   NaN      0      0  239853   0.0   NaN        S  \n",
       "302  19.0      0      0    LINE   0.0   NaN        S  \n",
       "413   NaN      0      0  239853   0.0   NaN        S  \n",
       "466   NaN      0      0  239853   0.0   NaN        S  \n",
       "481   NaN      0      0  239854   0.0   NaN        S  \n",
       "597  49.0      0      0    LINE   0.0   NaN        S  \n",
       "633   NaN      0      0  112052   0.0   NaN        S  \n",
       "674   NaN      0      0  239856   0.0   NaN        S  \n",
       "732   NaN      0      0  239855   0.0   NaN        S  \n",
       "806  39.0      0      0  112050   0.0   A36        S  \n",
       "815   NaN      0      0  112058   0.0  B102        S  \n",
       "822  38.0      0      0   19972   0.0   NaN        S  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.Fare == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsciamma\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py:798: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = getattr(x, name)(y)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "invalid type comparison",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-4c67401e22a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Fare'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\jsciamma\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, other, axis)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m                 raise TypeError('Could not compare %s type with Series' %\n",
      "\u001b[1;32mC:\\Users\\jsciamma\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mna_op\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    798\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"invalid type comparison\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    801\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: invalid type comparison"
     ]
    }
   ],
   "source": [
    "sum(train['Fare']=='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train[fields], train['Survived'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic=X_train.copy()\n",
    "titanic['Survived']=y_train\n",
    "titanic['Sex'] = np.where(titanic['Sex'] == 'male', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 668 entries, 105 to 684\n",
      "Data columns (total 5 columns):\n",
      "Pclass      668 non-null int64\n",
      "Sex         668 non-null int32\n",
      "SibSp       668 non-null int64\n",
      "Parch       668 non-null int64\n",
      "Survived    668 non-null int64\n",
      "dtypes: int32(1), int64(4)\n",
      "memory usage: 28.7 KB\n"
     ]
    }
   ],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr_matrix=titanic.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'titanic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-532-daf03dca2d35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitanic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Survived'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Sex'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Pclass'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maggfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'titanic' is not defined"
     ]
    }
   ],
   "source": [
    "pd.pivot_table(titanic, values='Survived', columns = 'Sex', index='Pclass', aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Sex</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.19222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Sex              0        1\n",
       "Survived  0.753247  0.19222"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(titanic, values='Survived', columns = 'Sex',  aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pclass</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>0.613497</td>\n",
       "      <td>0.492754</td>\n",
       "      <td>0.245232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pclass           1         2         3\n",
       "Survived  0.613497  0.492754  0.245232"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(titanic, values='Survived', columns = 'Pclass',  aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    1.000000\n",
       "Parch       0.081584\n",
       "SibSp      -0.050014\n",
       "Pclass     -0.326264\n",
       "Sex        -0.548061\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix[\"Survived\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic['WomanInFirst'] = (1-titanic['Sex']) * (titanic['Pclass']==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    597\n",
       "1     71\n",
       "Name: WomanInFirst, dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic['WomanInFirst'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived        1.000000\n",
       "WomanInFirst    0.404806\n",
       "Parch           0.081584\n",
       "SibSp          -0.050014\n",
       "Pclass         -0.326264\n",
       "Sex            -0.548061\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix=titanic.corr()\n",
    "corr_matrix[\"Survived\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train[fields], train['Survived'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "Pclass = X_train.Pclass\n",
    "Pclassencoder = LabelBinarizer(sparse_output=False)\n",
    "Pclassencoder.fit(Pclass)\n",
    "Pclass_encoded = Pclassencoder.transform(Pclass)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Sex = X_train.Sex\n",
    "Sexencoder = LabelBinarizer(sparse_output=False)\n",
    "Sexencoder.fit(Sex)\n",
    "Sex_encoded = Sexencoder.transform(Sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Embarked = X_train.Embarked\n",
    "Embarkedencoder = LabelBinarizer(sparse_output=False)\n",
    "Embarkedencoder.fit(Embarked)\n",
    "Embarked_encoded = Embarkedencoder.transform(Embarked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Master', 'Miss', 'Mr', 'Mrs'], \n",
       "      dtype='<U6')"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Title = X_train.Title\n",
    "Titleencoder = LabelBinarizer(sparse_output=False)\n",
    "Titleencoder.fit(Title)\n",
    "Title_encoded = Titleencoder.transform(Title)\n",
    "Title_encoded\n",
    "Titleencoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       ..., \n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 1, 0]], dtype=int32)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SibSp = X_train.Title\n",
    "SibSpencoder = LabelBinarizer(sparse_output=False)\n",
    "SibSpencoder.fit(SibSp)\n",
    "SibSp_encoded = SibSpencoder.transform(Title)\n",
    "SibSp_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     891\n",
       "unique      3\n",
       "top         S\n",
       "freq      646\n",
       "Name: Embarked, dtype: object"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Embarked.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## last check before preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      "PassengerId     891 non-null int64\n",
      "Survived        891 non-null int64\n",
      "Pclass          891 non-null int64\n",
      "Name            891 non-null object\n",
      "Sex             891 non-null object\n",
      "Age             714 non-null float64\n",
      "SibSp           891 non-null int64\n",
      "Parch           891 non-null int64\n",
      "Ticket          891 non-null object\n",
      "Fare            891 non-null float64\n",
      "Cabin           204 non-null object\n",
      "Embarked        891 non-null object\n",
      "Title           891 non-null object\n",
      "WomanInThird    891 non-null bool\n",
      "ManInFirst      891 non-null bool\n",
      "dtypes: bool(2), float64(2), int64(5), object(6)\n",
      "memory usage: 71.4+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex \n",
      "\n",
      "data type  object \n",
      "\n",
      "value counts:\n",
      " male      577\n",
      "female    314\n",
      "Name: Sex, dtype: int64 \n",
      "\n",
      "Title \n",
      "\n",
      "data type  object \n",
      "\n",
      "value counts:\n",
      " Mr        531\n",
      "Miss      185\n",
      "Mrs       129\n",
      "Master     40\n",
      "Rev         6\n",
      "Name: Title, dtype: int64 \n",
      "\n",
      "Embarked \n",
      "\n",
      "data type  object \n",
      "\n",
      "value counts:\n",
      " S    646\n",
      "C    168\n",
      "Q     77\n",
      "Name: Embarked, dtype: int64 \n",
      "\n",
      "WomanInThird \n",
      "\n",
      "data type  bool \n",
      "\n",
      "value counts:\n",
      " False    747\n",
      "True     144\n",
      "Name: WomanInThird, dtype: int64 \n",
      "\n",
      "ManInFirst \n",
      "\n",
      "data type  bool \n",
      "\n",
      "value counts:\n",
      " False    772\n",
      "True     119\n",
      "Name: ManInFirst, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in['Sex', 'Title', 'Embarked', 'WomanInThird', 'ManInFirst']:\n",
    "    print(c, \"\\n\")\n",
    "    print(\"data type \", train[c].dtype, \"\\n\")\n",
    "    print(\"value counts:\\n\", train[c].value_counts(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data type  int64 \n",
      "\n",
      "value counts:\n",
      " 3    491\n",
      "1    216\n",
      "2    184\n",
      "Name: Pclass, dtype: int64 \n",
      "\n",
      "data type  int64 \n",
      "\n",
      "value counts:\n",
      " 0    608\n",
      "1    209\n",
      "2     28\n",
      "4     18\n",
      "3     16\n",
      "8      7\n",
      "5      5\n",
      "Name: SibSp, dtype: int64 \n",
      "\n",
      "data type  int64 \n",
      "\n",
      "value counts:\n",
      " 0    678\n",
      "1    118\n",
      "2     80\n",
      "5      5\n",
      "3      5\n",
      "4      4\n",
      "6      1\n",
      "Name: Parch, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in ['Pclass', 'SibSp', 'Parch']:\n",
    "    print(\"data type \", train[c].dtype, \"\\n\")\n",
    "    print(\"value counts:\\n\", train[c].value_counts(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#X_train_converted = np.c_[X_train.drop(['Pclass', 'Sex', 'Embarked', 'Title', 'SibSp'], axis=1), \n",
    "#                          Pclass_encoded, Sex_encoded, Embarked_encoded, Title_encoded, SibSp_encoded]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, train['Survived'], random_state=0)\n",
    "\n",
    "#num_attribs = ['Pclass', 'SibSp' ,'Parch']\n",
    "#cat_attribs = ['Sex', 'Embarked', 'Title']\n",
    "# 'WomanInThird'\n",
    "num_attribs = ['Pclass', 'SibSp', 'Parch', 'WomanInThird', 'ManInFirst']\n",
    "cat_attribs = ['Sex', 'Embarked', 'Title']\n",
    "#cat_attribs = ['Title']\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(num_attribs)),\n",
    "    ('encoder', OneHotEncoder()),\n",
    "])\n",
    "\n",
    "# can't get LabelBinarizer to work on a list of columns so creating a list of pipelines\n",
    "cat_pipelines = [( cat,\n",
    "    Pipeline([\n",
    "    ('selector', DataFrameSelector(cat)),\n",
    "    ('encoder', LabelBinarizer()),\n",
    "])) for cat in cat_attribs]\n",
    "\n",
    "cat_pipeline = FeatureUnion(transformer_list = cat_pipelines)\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list =[\n",
    "    (\"num_pipeline\", num_pipeline),\n",
    "    (\"cat_pipeline\", cat_pipeline),    \n",
    "])\n",
    "\n",
    "X_train_converted = full_pipeline.fit_transform(X_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class FieldConverter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        SexInt = np.where(X['Sex'] == 'male', 1, 0)\n",
    "        return np.c_[X.drop('Sex', axis=1), SexInt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FieldBinarizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        SexInt = np.where(X['Sex'] == 'male', 1, 0)\n",
    "        return np.c_[X.drop('Sex', axis=1), SexInt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train[fields], train['Survived'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "field_converter=FieldConverter()\n",
    "X_train_converted = field_converter.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass     Sex  SibSp  Parch\n",
       "105       3    male      0      0\n",
       "68        3  female      4      2\n",
       "253       3    male      1      0\n",
       "320       3    male      0      0\n",
       "706       2  female      0      0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 1, 0],\n",
       "       [2, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [1, 0, 1, ..., 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_converted2 = X_train_converted[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [4, 2, 0],\n",
       "       [1, 0, 1],\n",
       "       ..., \n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_converted2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Field conversion from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(668, 25)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_converted.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#log_reg_clf = Pipeline((\n",
    "#    (\"scaler\", StandardScaler()),\n",
    "#    (\"log_reg\", LogisticRegression())))\n",
    "\n",
    "log_reg_clf = LogisticRegression()\n",
    "log_reg_clf.fit(X_train_converted, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83532934131736525"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(log_reg_clf.predict(X_train_converted)==y_train)/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83245137946630476"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(log_reg_clf, X_train_converted, y_train,\n",
    "                        scoring=\"accuracy\", cv=10)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=1, oob_score=True, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_class = RandomForestClassifier(oob_score=True, n_estimators=100)\n",
    "forest_class.fit(X_train_converted, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85479041916167664"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(forest_class.predict(X_train_converted)==y_train)/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79491017964071853"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_class.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05973113,  0.03049769,  0.08866177,  0.03545565,  0.02900832,\n",
       "        0.00675961,  0.00862808,  0.01433072,  0.00419964,  0.00481293,\n",
       "        0.02982781,  0.01966544,  0.0154364 ,  0.00130057,  0.00126667,\n",
       "        0.00460494,  0.00161985,  0.16715138,  0.024126  ,  0.01806192,\n",
       "        0.02804414,  0.01917198,  0.04504818,  0.26221096,  0.08037823])"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_class.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.15560556,  0.38285714,  0.09663456,  0.15560556,  0.8771679 ,\n",
       "        0.15560556,  0.41439727,  0.15560556,  1.        ,  0.64242312,\n",
       "        0.64242312,  0.31361173,  0.09663456,  0.95953643,  1.        ,\n",
       "        1.        ,  0.15560556,  0.15560556,  1.        ,  0.15560556,\n",
       "        0.1067334 ,  1.        ,  0.41439727,  0.64242312,  0.15560556,\n",
       "        0.15560556,  0.69333333,  0.15560556,  0.        ,  0.46833333,\n",
       "        0.1067334 ,  0.14285714,  0.59984163,  0.64242312,  0.15560556,\n",
       "        0.29333333,  0.15560556,  0.15560556,  0.        ,  0.15560556,\n",
       "        0.31361173,  0.15560556,  0.09663456,  0.64242312,  0.31361173,\n",
       "        0.31361173,  1.        ,  0.        ,  0.18841991,  0.59984163,\n",
       "        0.60093795,  0.18841991,  0.15560556,  0.15560556,  0.15560556,\n",
       "        0.64242312,  0.64242312,  0.15560556,  0.59984163,  0.31361173,\n",
       "        0.95953643,  0.15560556,  0.15560556,  0.41439727,  0.        ,\n",
       "        0.1067334 ,  0.31361173,  0.1067334 ,  0.08116356,  0.61277778,\n",
       "        1.        ,  0.8771679 ,  0.1067334 ,  0.1067334 ,  0.31361173,\n",
       "        0.31361173,  0.1067334 ,  1.        ,  0.15560556,  0.09663456,\n",
       "        0.71333333,  0.31361173,  0.64242312,  0.31361173,  0.38285714,\n",
       "        0.8771679 ,  0.15560556,  0.1067334 ,  0.2       ,  0.48301587,\n",
       "        0.15560556,  0.15560556,  0.31361173,  0.4998297 ,  0.15560556,\n",
       "        0.        ,  0.15560556,  0.15560556,  0.59984163,  0.95953643,\n",
       "        0.8771679 ,  0.4998297 ,  0.09663456,  0.4998297 ,  0.15560556,\n",
       "        0.15560556,  0.15560556,  0.8771679 ,  0.15560556,  0.31666667,\n",
       "        0.1067334 ,  0.41439727,  0.15560556,  0.15560556,  0.31361173,\n",
       "        1.        ,  0.15560556,  0.15560556,  0.18841991,  0.15560556,\n",
       "        0.1067334 ,  0.4998297 ,  0.4998297 ,  0.8771679 ,  0.1067334 ,\n",
       "        0.15560556,  0.31361173,  1.        ,  0.8771679 ,  0.15560556,\n",
       "        0.15560556,  0.78106421,  0.15560556,  1.        ,  0.64242312,\n",
       "        0.1067334 ,  0.45      ,  0.        ,  1.        ,  1.        ,\n",
       "        1.        ,  0.64242312,  0.95953643,  0.64242312,  0.15560556,\n",
       "        0.15560556,  0.95953643,  0.15560556,  0.        ,  0.8771679 ,\n",
       "        0.63260234,  0.        ,  0.31361173,  0.31361173,  0.15560556,\n",
       "        0.69333333,  0.        ,  0.8771679 ,  0.15560556,  0.64242312,\n",
       "        0.15560556,  0.15560556,  0.15560556,  0.15560556,  0.15560556,\n",
       "        0.64242312,  0.        ,  0.15560556,  0.95953643,  0.48301587,\n",
       "        0.15560556,  0.15560556,  0.31361173,  0.69333333,  0.61944444,\n",
       "        0.8771679 ,  0.08116356,  0.15560556,  1.        ,  0.31361173,\n",
       "        0.95953643,  0.15560556,  0.2       ,  0.31361173,  0.59984163,\n",
       "        0.38285714,  0.15560556,  0.1067334 ,  0.15560556,  0.64242312,\n",
       "        0.15560556,  0.15560556,  0.1067334 ,  0.09663456,  0.31361173,\n",
       "        0.31361173,  0.31361173,  0.31361173,  0.15560556,  0.31361173,\n",
       "        0.15560556,  0.15560556,  0.35      ,  0.15560556,  1.        ,\n",
       "        0.09663456,  0.09663456,  0.        ,  0.        ,  0.95953643,\n",
       "        0.78106421,  0.31361173,  0.15560556,  0.1067334 ,  0.78106421,\n",
       "        0.31361173,  0.15560556,  0.15560556,  0.8771679 ,  0.71333333,\n",
       "        0.18841991,  0.31361173,  0.15560556,  0.1067334 ,  0.1067334 ,\n",
       "        0.15560556,  0.15560556,  0.64242312,  0.08116356,  0.78106421,\n",
       "        0.09663456,  0.1067334 ,  0.1067334 ,  0.15560556,  0.69333333,\n",
       "        0.15560556,  0.41190476,  0.15560556,  0.09663456,  0.4998297 ,\n",
       "        0.15560556,  0.8771679 ,  1.        ,  1.        ,  0.15560556,\n",
       "        0.15560556,  1.        ,  1.        ,  1.        ,  0.1067334 ,\n",
       "        0.95953643,  0.15560556,  0.1067334 ,  0.59984163,  0.15560556,\n",
       "        0.31361173,  0.09663456,  0.41439727,  0.1067334 ,  0.8771679 ,\n",
       "        0.69333333,  0.15560556,  0.15560556,  0.8771679 ,  0.15560556,\n",
       "        0.59984163,  0.35      ,  0.95953643,  0.09663456,  0.18841991,\n",
       "        0.31361173,  0.61277778,  0.15560556,  0.        ,  0.31361173,\n",
       "        0.15560556,  0.15560556,  0.64242312,  0.64242312,  0.16833333,\n",
       "        0.31361173,  0.1       ,  0.15560556,  0.        ,  1.        ,\n",
       "        0.15560556,  0.69333333,  0.15560556,  0.15560556,  0.15560556,\n",
       "        0.15560556,  1.        ,  0.31361173,  0.31361173,  0.4998297 ,\n",
       "        0.07      ,  0.64242312,  0.95953643,  0.41439727,  1.        ,\n",
       "        0.60093795,  0.15560556,  0.09663456,  0.31666667,  0.1067334 ,\n",
       "        0.31361173,  0.15560556,  0.1067334 ,  0.8771679 ,  0.15560556,\n",
       "        0.8771679 ,  0.15560556,  0.1067334 ,  0.61277778,  0.95953643,\n",
       "        0.15560556,  1.        ,  0.64242312,  0.95953643,  0.15560556,\n",
       "        0.15560556,  0.4998297 ,  0.        ,  0.95953643,  0.15560556,\n",
       "        0.09663456,  0.64242312,  0.31361173,  0.15560556,  1.        ,\n",
       "        0.95953643,  0.31361173,  0.1067334 ,  0.31361173,  0.15560556,\n",
       "        0.41439727,  1.        ,  0.15560556,  0.8771679 ,  0.1067334 ,\n",
       "        1.        ,  0.15560556,  1.        ,  0.15560556,  0.15560556,\n",
       "        0.64242312,  0.60093795,  0.64242312,  0.31361173,  0.15560556,\n",
       "        0.78106421,  0.15560556,  0.06      ,  0.31361173,  0.        ,\n",
       "        0.1067334 ,  0.15560556,  1.        ,  0.29333333,  0.15560556,\n",
       "        0.15560556,  0.15560556,  0.09663456,  0.95953643,  0.1067334 ,\n",
       "        0.31361173,  0.        ,  0.64242312,  0.        ,  0.15560556,\n",
       "        0.15560556,  1.        ,  1.        ,  0.        ,  0.41190476,\n",
       "        1.        ,  0.08116356,  0.06      ,  0.        ,  0.15560556,\n",
       "        0.31361173,  0.15560556,  0.15560556,  0.15560556,  0.41439727,\n",
       "        1.        ,  0.64242312,  1.        ,  0.8771679 ,  1.        ,\n",
       "        0.8771679 ,  0.        ,  0.15560556,  0.15560556,  0.60093795,\n",
       "        0.1067334 ,  0.        ,  0.15560556,  0.64242312,  0.15560556,\n",
       "        0.64242312,  0.15560556,  0.        ,  0.        ,  0.07      ,\n",
       "        0.31361173,  0.59984163,  0.64242312,  0.18841991,  0.15560556,\n",
       "        0.1067334 ,  0.        ,  0.15560556,  1.        ,  1.        ,\n",
       "        0.41439727,  0.61277778,  0.        ,  0.95953643,  0.15560556,\n",
       "        0.29333333,  0.1067334 ,  0.4998297 ,  0.1067334 ,  0.92857143,\n",
       "        0.64242312,  0.92857143,  0.95953643,  0.        ,  0.8771679 ,\n",
       "        0.15560556,  0.15560556,  0.61277778,  0.41190476,  0.09663456,\n",
       "        1.        ,  0.1067334 ,  0.15560556,  0.38285714,  0.15560556,\n",
       "        0.4998297 ,  0.8771679 ,  0.15560556,  0.08116356,  1.        ,\n",
       "        0.2       ,  0.15560556,  0.15560556,  0.1067334 ,  0.15560556,\n",
       "        0.15560556,  0.15560556,  0.41439727,  0.4998297 ,  0.46833333,\n",
       "        0.15560556,  0.15560556,  0.1067334 ,  0.15560556,  0.        ,\n",
       "        0.61277778,  0.64242312,  0.15560556,  0.15560556,  0.59984163,\n",
       "        1.        ,  0.15560556,  0.46      ,  0.15560556,  0.64242312,\n",
       "        1.        ,  1.        ,  0.31361173,  0.15560556,  0.15560556,\n",
       "        0.825     ,  0.15560556,  0.15560556,  0.31361173,  0.1067334 ,\n",
       "        0.1067334 ,  0.41439727,  0.34357143,  0.08116356,  0.15560556,\n",
       "        0.55      ,  0.31361173,  0.1067334 ,  0.15560556,  0.15560556,\n",
       "        0.15560556,  0.4998297 ,  0.15560556,  0.15560556,  0.31361173,\n",
       "        0.15560556,  1.        ,  0.8771679 ,  0.46833333,  0.        ,\n",
       "        0.15560556,  0.31361173,  0.64242312,  0.48301587,  0.15560556,\n",
       "        0.95953643,  0.1067334 ,  0.15560556,  0.31361173,  0.60093795,\n",
       "        0.15560556,  0.15560556,  0.15560556,  0.15560556,  0.15560556,\n",
       "        0.61277778,  0.09663456,  0.15560556,  0.31361173,  1.        ,\n",
       "        0.95953643,  0.29333333,  0.64242312,  0.15560556,  1.        ,\n",
       "        0.95953643,  1.        ,  0.        ,  0.15560556,  1.        ,\n",
       "        1.        ,  0.78106421,  0.15560556,  0.1067334 ,  0.31361173,\n",
       "        0.71333333,  0.15560556,  0.08116356,  0.8771679 ,  0.1067334 ,\n",
       "        0.15560556,  1.        ,  0.34357143,  0.15560556,  0.15560556,\n",
       "        0.31361173,  0.15560556,  0.31361173,  0.4998297 ,  0.31361173,\n",
       "        1.        ,  0.        ,  0.64242312,  0.64242312,  0.55      ,\n",
       "        0.8771679 ,  0.1067334 ,  0.4998297 ,  0.95953643,  0.15560556,\n",
       "        0.29333333,  0.15560556,  0.78106421,  0.15560556,  0.15560556,\n",
       "        1.        ,  0.91      ,  0.15560556,  0.31361173,  0.15560556,\n",
       "        0.1067334 ,  0.15560556,  0.63260234,  0.15560556,  0.        ,\n",
       "        0.15560556,  0.95953643,  0.64242312,  1.        ,  0.        ,\n",
       "        0.15560556,  0.8771679 ,  0.31361173,  0.        ,  0.15560556,\n",
       "        0.1067334 ,  0.15560556,  0.64242312,  0.31361173,  1.        ,\n",
       "        0.38285714,  1.        ,  0.15560556,  0.15560556,  0.95953643,\n",
       "        0.15560556,  0.09663456,  0.15560556,  0.59984163,  0.15560556,\n",
       "        0.15560556,  0.18841991,  0.15560556,  0.15560556,  0.34357143,\n",
       "        0.78106421,  0.59984163,  0.48301587,  0.91      ,  0.64242312,\n",
       "        0.61944444,  0.15560556,  0.15560556,  0.15560556,  1.        ,\n",
       "        0.15560556,  0.1067334 ,  0.08116356,  0.4998297 ,  0.09663456,\n",
       "        0.64242312,  0.1067334 ,  0.1067334 ,  0.48301587,  0.2       ,\n",
       "        0.34357143,  0.64242312,  0.83333333,  0.95953643,  0.08116356,\n",
       "        0.29333333,  0.825     ,  0.59984163,  0.15560556,  0.41439727,\n",
       "        0.60093795,  0.15560556,  0.64242312,  0.1067334 ,  0.15560556,\n",
       "        0.95953643,  0.64242312,  1.        ,  0.78106421,  0.31361173,\n",
       "        0.15560556,  0.1067334 ,  1.        ,  0.1067334 ,  0.60093795,\n",
       "        0.64242312,  1.        ,  1.        ,  0.1067334 ,  0.4998297 ,\n",
       "        0.15560556,  1.        ,  0.1067334 ,  0.1067334 ,  0.78106421,\n",
       "        0.64242312,  0.31361173,  0.41190476,  1.        ,  0.59984163,\n",
       "        0.15560556,  0.59984163,  0.60093795])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_reg.predict(X_train_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81139755766621435"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_class = RandomForestClassifier( n_estimators=100)\n",
    "forest_class.fit(X_train_converted, y_train)\n",
    "scores = cross_val_score(forest_class, X_train_converted, y_train,\n",
    "                        scoring=\"accuracy\", cv=10)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85479041916167664"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "polynomial_svm_clf = Pipeline((\n",
    "    (\"poly_features\", PolynomialFeatures(degree=2)),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svm_clf\", LinearSVC(C=0.5, loss=\"hinge\"))))\n",
    "\n",
    "polynomial_svm_clf.fit(X_train_converted, y_train)\n",
    "(polynomial_svm_clf.predict(X_train_converted) == y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7964269561284486"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(polynomial_svm_clf, X_train_converted, y_train,\n",
    "                        scoring=\"accuracy\", cv=10)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83383233532934131"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "poly_kernel_svm_clf = Pipeline((\n",
    "    ('scaler', StandardScaler()),\n",
    "    (\"svm_clf\", SVC(kernel=\"poly\", degree=3, coef0=1, C=0.01))))\n",
    "poly_kernel_svm_clf.fit(X_train_converted, y_train)\n",
    "(poly_kernel_svm_clf.predict(X_train_converted) == y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82643600180913612"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(poly_kernel_svm_clf, X_train_converted, y_train,\n",
    "                        scoring=\"accuracy\", cv=10)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85479041916167664"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "rbf_kernel_svm_clf = Pipeline((\n",
    "    ('scaler', StandardScaler()),\n",
    "    (\"rbf_clf\", SVC(kernel=\"rbf\", gamma=1, C=0.1))))\n",
    "rbf_kernel_svm_clf.fit(X_train_converted, y_train)\n",
    "(rbf_kernel_svm_clf.predict(X_train_converted) == y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75590230664857527"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(rbf_kernel_svm_clf, X_train_converted, y_train,\n",
    "                        scoring=\"accuracy\", cv=10)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81897331524197203"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = Pipeline((\n",
    "    ('scaler', StandardScaler()),\n",
    "    (\"knn_clf\", KNeighborsClassifier(n_neighbors=10, weights='uniform'))\n",
    "))\n",
    "knn_clf.fit(X_train_converted, y_train)\n",
    "scores = cross_val_score(knn_clf, X_train_converted, y_train,\n",
    "                        scoring=\"accuracy\", cv=10)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "?KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83245137946630476"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('rf', forest_class), ('poly', poly_kernel_svm_clf), ('logreg', log_reg)]\n",
    ")\n",
    "\n",
    "voting_clf.fit(X_train_converted, y_train)\n",
    "scores = cross_val_score(voting_clf, X_train_converted, y_train,\n",
    "                        scoring=\"accuracy\", cv=10)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fit (streamlined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "def InitModels():\n",
    "    models=[]\n",
    "    models.append((\"log_reg_clf\", LogisticRegression()))\n",
    "    models.append((\"forest_class\",  RandomForestClassifier(n_estimators=100)))\n",
    "    models.append((\"poly_svm_clf\", Pipeline((\n",
    "        (\"poly_features\", PolynomialFeatures(degree=2)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svm_clf\", LinearSVC(C=0.5, loss=\"hinge\"))))\n",
    "                  ))\n",
    "    models.append((\"rbf_kernel_svm_clf\", Pipeline((\n",
    "        ('scaler', StandardScaler()),\n",
    "        (\"rbf_clf\", SVC(kernel=\"rbf\", gamma=1, C=0.1))))\n",
    "                  ))\n",
    "    models.append((\"poly_kernel_svm_clf\", Pipeline((\n",
    "        ('scaler', StandardScaler()),\n",
    "        (\"svm_clf\", SVC(kernel=\"poly\", degree=3, coef0=1, C=0.01))))\n",
    "                  ))\n",
    "    models.append((\"knn_clf\", Pipeline((\n",
    "        ('scaler', StandardScaler()),\n",
    "        (\"knn_clf\", KNeighborsClassifier(n_neighbors=1, weights='uniform', algorithm='brute'))))\n",
    "        ))\n",
    "\n",
    "    models.append((\"voting_clf\", VotingClassifier(\n",
    "        estimators=[models[0], models[4]])\n",
    "                  ))\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_reg_clf  cross validated score:  0.833966530981\n",
      "forest_class  cross validated score:  0.806897331524\n",
      "poly_svm_clf  cross validated score:  0.79038896427\n",
      "rbf_kernel_svm_clf  cross validated score:  0.760379918589\n",
      "poly_kernel_svm_clf  cross validated score:  0.827928539123\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors > 0. Got 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-710-3e8584d4b2bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mmodels_full\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInitModels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mprint_cv_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels_full\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_converted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mfit_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels_full\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_converted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mprint_accuracy_training_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels_full\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_converted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-710-3e8584d4b2bb>\u001b[0m in \u001b[0;36mprint_cv_scores\u001b[1;34m(models, X_train_converted, y_train)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         scores = cross_val_score(m[1], X_train_converted, y_train,\n\u001b[1;32m----> 4\u001b[1;33m                             scoring=\"accuracy\", cv=10)\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\" cross validated score: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Patrick\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                                               fit_params)\n\u001b[1;32m--> 140\u001b[1;33m                       for train, test in cv_iter)\n\u001b[0m\u001b[0;32m    141\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Patrick\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Patrick\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Patrick\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Patrick\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Patrick\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Patrick\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Patrick\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Patrick\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Patrick\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Patrick\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    784\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    787\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Patrick\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 raise ValueError(\n\u001b[0;32m    254\u001b[0m                     \u001b[1;34m\"Expected n_neighbors > 0. Got %d\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m                 )\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected n_neighbors > 0. Got 0"
     ]
    }
   ],
   "source": [
    "def print_cv_scores(models, X_train_converted, y_train):\n",
    "    for m in models:\n",
    "        scores = cross_val_score(m[1], X_train_converted, y_train,\n",
    "                            scoring=\"accuracy\", cv=10)\n",
    "        print(m[0], \" cross validated score: \", scores.mean())\n",
    "\n",
    "def fit_models(models, X_train_converted, y_train):\n",
    "    for m in models:\n",
    "        m[1].fit(X_train_converted, y_train)\n",
    "        \n",
    "def print_accuracy_training_set(models, X_train_converted, y_train):\n",
    "    for m in models:\n",
    "        accuracy = (m[1].predict(X_train_converted) == y_train).mean()\n",
    "        print(m[0], \" training set accuracy: \", accuracy)\n",
    "        \n",
    "models_full = InitModels()\n",
    "print_cv_scores(models_full, X_train_converted, y_train)\n",
    "fit_models(models_full, X_train_converted, y_train)\n",
    "print_accuracy_training_set(models_full, X_train_converted, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 708,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_full[5][1].score(X_train_converted, y_train)\n",
    "models_full[5][1].classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_cache',\n",
       " '_abc_negative_cache',\n",
       " '_abc_negative_cache_version',\n",
       " '_abc_registry',\n",
       " '_estimator_type',\n",
       " '_final_estimator',\n",
       " '_fit',\n",
       " '_get_param_names',\n",
       " '_get_params',\n",
       " '_inverse_transform',\n",
       " '_pairwise',\n",
       " '_replace_step',\n",
       " '_set_params',\n",
       " '_transform',\n",
       " '_validate_names',\n",
       " '_validate_steps',\n",
       " 'classes_',\n",
       " 'decision_function',\n",
       " 'fit',\n",
       " 'fit_predict',\n",
       " 'fit_transform',\n",
       " 'get_params',\n",
       " 'inverse_transform',\n",
       " 'named_steps',\n",
       " 'predict',\n",
       " 'predict_log_proba',\n",
       " 'predict_proba',\n",
       " 'score',\n",
       " 'set_params',\n",
       " 'steps',\n",
       " 'transform']"
      ]
     },
     "execution_count": 703,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(models_full[5][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_reg_clf  cross validated score:  0.663888888889\n",
      "forest_class  cross validated score:  0.651388888889\n",
      "poly_svm_clf  cross validated score:  0.6625\n",
      "rbf_kernel_svm_clf  cross validated score:  0.675\n",
      "poly_kernel_svm_clf  cross validated score:  0.675\n",
      "knn_clf  cross validated score:  0.675\n",
      "voting_clf  cross validated score:  0.675\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "log_reg_clf  training set accuracy:  0.707865168539\n",
      "forest_class  training set accuracy:  0.719101123596\n",
      "poly_svm_clf  training set accuracy:  0.707865168539\n",
      "rbf_kernel_svm_clf  training set accuracy:  0.674157303371\n",
      "poly_kernel_svm_clf  training set accuracy:  0.674157303371\n",
      "knn_clf  training set accuracy:  0.707865168539\n",
      "voting_clf  training set accuracy:  0.674157303371\n"
     ]
    }
   ],
   "source": [
    "# cross validate on subsets\n",
    "models_ManInFirst = InitModels()\n",
    "\n",
    "print_cv_scores(models_ManInFirst, X_train_converted[X_train.ManInFirst], y_train[X_train.ManInFirst])\n",
    "print(\"\\n\")\n",
    "fit_models(models_ManInFirst, X_train_converted[X_train.ManInFirst], y_train[X_train.ManInFirst])\n",
    "print(\"\\n\")\n",
    "print_accuracy_training_set(models_ManInFirst, X_train_converted[X_train.ManInFirst], y_train[X_train.ManInFirst])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_reg_clf  cross validated score:  0.598282828283\n",
      "forest_class  cross validated score:  0.497171717172\n",
      "poly_svm_clf  cross validated score:  0.499898989899\n",
      "rbf_kernel_svm_clf  cross validated score:  0.510101010101\n",
      "poly_kernel_svm_clf  cross validated score:  0.539191919192\n",
      "knn_clf  cross validated score:  0.404646464646\n",
      "voting_clf  cross validated score:  0.598282828283\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "log_reg_clf  training set accuracy:  0.686274509804\n",
      "forest_class  training set accuracy:  0.735294117647\n",
      "poly_svm_clf  training set accuracy:  0.735294117647\n",
      "rbf_kernel_svm_clf  training set accuracy:  0.725490196078\n",
      "poly_kernel_svm_clf  training set accuracy:  0.539215686275\n",
      "knn_clf  training set accuracy:  0.598039215686\n",
      "voting_clf  training set accuracy:  0.686274509804\n"
     ]
    }
   ],
   "source": [
    "# cross validate on subsets\n",
    "models_WomanInThird = InitModels()\n",
    "\n",
    "print_cv_scores(models_WomanInThird, X_train_converted[X_train.WomanInThird], y_train[X_train.WomanInThird])\n",
    "print(\"\\n\")\n",
    "fit_models(models_WomanInThird, X_train_converted[X_train.WomanInThird], y_train[X_train.WomanInThird])\n",
    "print(\"\\n\")\n",
    "print_accuracy_training_set(models_WomanInThird, X_train_converted[X_train.WomanInThird], y_train[X_train.WomanInThird])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_reg_clf  training set accuracy:  0.841317365269\n",
      "forest_class  training set accuracy:  0.854790419162\n",
      "poly_svm_clf  training set accuracy:  0.850299401198\n",
      "rbf_kernel_svm_clf  training set accuracy:  0.854790419162\n",
      "poly_kernel_svm_clf  training set accuracy:  0.833832335329\n",
      "knn_clf  training set accuracy:  0.826347305389\n",
      "voting_clf  training set accuracy:  0.841317365269\n"
     ]
    }
   ],
   "source": [
    "for m in models:\n",
    "    accuracy = (m[1].predict(X_train_converted) == y_train).mean()\n",
    "    print(m[0], \" training set accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Sex</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.684783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.913793</td>\n",
       "      <td>0.912500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.886792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Sex       female      male\n",
       "Pclass                    \n",
       "1       0.957746  0.684783\n",
       "2       0.913793  0.912500\n",
       "3       0.686275  0.886792"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (models[0][1].predict(X_train_converted) == y_train).astype(int)\n",
    "X_train2 = X_train.copy()\n",
    "X_train2['accuracy'] = accuracy\n",
    "X_train2['predicted'] = models[0][1].predict(X_train_converted)\n",
    "X_train2.pivot_table(index=\"Pclass\", columns=['Sex'], values=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Miss</th>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.786667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs</th>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Survived  predicted\n",
       "Title                     \n",
       "Miss   0.520000   0.786667\n",
       "Mrs    0.518519   0.888889"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = X_train2[(X_train2.Pclass==3) & (X_train2.Sex=='female') ]\n",
    "df.pivot_table(index='Title', values=['predicted', 'Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Miss</th>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs</th>\n",
       "      <td>0.518519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Survived\n",
       "Title          \n",
       "Miss   0.520000\n",
       "Mrs    0.518519"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot_table(index='Title', values='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?X_train.pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `train2.pivotTable` not found.\n"
     ]
    }
   ],
   "source": [
    "train2.pivotTable?\n",
    "pd.pivot_table(train[train.Pclass==1], values='Fare', columns = 'Embarked', aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `np.as_type` not found.\n"
     ]
    }
   ],
   "source": [
    "a=True\n",
    "?np.as_type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_converted = full_pipeline.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_reg_clf  testing set accuracy:  0.816143497758\n",
      "forest_class  testing set accuracy:  0.80269058296\n",
      "poly_svm_clf  testing set accuracy:  0.834080717489\n",
      "rbf_kernel_svm_clf  testing set accuracy:  0.775784753363\n",
      "poly_kernel_svm_clf  testing set accuracy:  0.811659192825\n",
      "knn_clf  testing set accuracy:  0.816143497758\n",
      "voting_clf  testing set accuracy:  0.816143497758\n"
     ]
    }
   ],
   "source": [
    "for m in models:\n",
    "    accuracy = (m[1].predict(X_test_converted) == y_test).mean()\n",
    "    print(m[0], \" testing set accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80717488789237668"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(log_reg_clf.predict(X_test_converted)==y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81165919282511212"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(voting_clf.predict(X_test_converted)==y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=\n",
    "for model_name, model in z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
